{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\fastcampus_ml\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv('./data/kc_house_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 집 고유아이디\\ndate: 집이 팔린 날짜\\nprice: 집 가격(타겟변수)\\nbedrooms: 주택당 침실개수\\nbathrooms: 주택당 화장실 개수\\nfloors: 전체 층 개수\\nwaterfront: 해변이 보이는지 (0, 1)\\ncondition: 집 청소상태 (1~5)\\ngrade: King County Grading System으로 인한 평점 (1~13)\\nyr_built: 집이 지어진 년도\\nyt_renovated: 집이 리모델링된 년도\\nzipcode: 우편번호\\nlat: 위도\\nlong: 경도\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 집 고유아이디\n",
    "date: 집이 팔린 날짜\n",
    "price: 집 가격(타겟변수)\n",
    "bedrooms: 주택당 침실개수\n",
    "bathrooms: 주택당 화장실 개수\n",
    "floors: 전체 층 개수\n",
    "waterfront: 해변이 보이는지 (0, 1)\n",
    "condition: 집 청소상태 (1~5)\n",
    "grade: King County Grading System으로 인한 평점 (1~13)\n",
    "yr_built: 집이 지어진 년도\n",
    "yt_renovated: 집이 리모델링된 년도\n",
    "zipcode: 우편번호\n",
    "lat: 위도\n",
    "long: 경도\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21613\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "ncar = data.shape[0]\n",
    "nvar = data.shape[1]\n",
    "\n",
    "print(ncar)\n",
    "print(nvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무의미하게 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명변수와 타겟변수를 분리, 학습/평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price']))\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=42) # 7:3 으로 학습/평가데이터 분리\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) #3 데이터 차원 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터를 선형회귀모형 적합 후 평가데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2776.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 18 Oct 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:36:19</td>     <th>  Log-Likelihood:    </th> <td>-2.0826e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15129</td>      <th>  AIC:               </th>  <td>4.165e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15120</td>      <th>  BIC:               </th>  <td>4.166e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td> 7.186e+06</td> <td> 1.73e+05</td> <td>   41.548</td> <td> 0.000</td> <td> 6.85e+06</td> <td> 7.52e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>    <td> 1.303e+05</td> <td> 3960.833</td> <td>   32.889</td> <td> 0.000</td> <td> 1.23e+05</td> <td> 1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>     <td>-2224.7910</td> <td> 2382.356</td> <td>   -0.934</td> <td> 0.350</td> <td>-6894.497</td> <td> 2444.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition</th>    <td> 1.641e+04</td> <td> 3169.013</td> <td>    5.178</td> <td> 0.000</td> <td> 1.02e+04</td> <td> 2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>       <td> 1946.3052</td> <td> 4336.838</td> <td>    0.449</td> <td> 0.654</td> <td>-6554.422</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>        <td> 1.956e+05</td> <td> 2199.540</td> <td>   88.924</td> <td> 0.000</td> <td> 1.91e+05</td> <td>    2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>   <td> 7.555e+05</td> <td> 2.26e+04</td> <td>   33.479</td> <td> 0.000</td> <td> 7.11e+05</td> <td>    8e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>     <td>-4300.7865</td> <td>   88.073</td> <td>  -48.832</td> <td> 0.000</td> <td>-4473.420</td> <td>-4128.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th> <td>   12.7325</td> <td>    5.043</td> <td>    2.525</td> <td> 0.012</td> <td>    2.847</td> <td>   22.618</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13447.374</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1684794.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.763</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>54.147</td>   <th>  Cond. No.          </th>  <td>1.82e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.82e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.595\n",
       "Model:                            OLS   Adj. R-squared:                  0.595\n",
       "Method:                 Least Squares   F-statistic:                     2776.\n",
       "Date:                Sun, 18 Oct 2020   Prob (F-statistic):               0.00\n",
       "Time:                        22:36:19   Log-Likelihood:            -2.0826e+05\n",
       "No. Observations:               15129   AIC:                         4.165e+05\n",
       "Df Residuals:                   15120   BIC:                         4.166e+05\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const         7.186e+06   1.73e+05     41.548      0.000    6.85e+06    7.52e+06\n",
       "bathrooms     1.303e+05   3960.833     32.889      0.000    1.23e+05    1.38e+05\n",
       "bedrooms     -2224.7910   2382.356     -0.934      0.350   -6894.497    2444.915\n",
       "condition     1.641e+04   3169.013      5.178      0.000    1.02e+04    2.26e+04\n",
       "floors        1946.3052   4336.838      0.449      0.654   -6554.422    1.04e+04\n",
       "grade         1.956e+05   2199.540     88.924      0.000    1.91e+05       2e+05\n",
       "waterfront    7.555e+05   2.26e+04     33.479      0.000    7.11e+05       8e+05\n",
       "yr_built     -4300.7865     88.073    -48.832      0.000   -4473.420   -4128.153\n",
       "yr_renovated    12.7325      5.043      2.525      0.012       2.847      22.618\n",
       "==============================================================================\n",
       "Omnibus:                    13447.374   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1684794.827\n",
       "Skew:                           3.763   Prob(JB):                         0.00\n",
       "Kurtosis:                      54.147   Cond. No.                     1.82e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.82e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sm_train_x = sm.add_constant(train_x, has_constant='add')\n",
    "sm_model = sm.OLS(train_y, sm_train_x)\n",
    "fitted_sm_model = sm_model.fit()\n",
    "fitted_sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_test_x = sm.add_constant(test_x, has_constant='add')\n",
    "sm_model_predict = fitted_sm_model.predict(sm_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239804.29670858168"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(sm_model_predict, test_y)) # RMSE 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging 구현을 통한 일반회귀모델과 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240129.8492463595\n",
      "239694.60448511862\n",
      "239948.1856794934\n",
      "241043.96577074117\n",
      "239716.2158658496\n",
      "239719.11064467524\n",
      "240594.3127601503\n",
      "240168.1261413766\n",
      "239994.7253154653\n",
      "240464.3018077149\n",
      "240219.35663294225\n",
      "240516.0714700639\n",
      "240320.10520395785\n",
      "240036.87593573207\n",
      "240111.9673038997\n",
      "240474.81941085326\n",
      "239619.90544941498\n",
      "239709.2269973137\n",
      "240438.55583696545\n",
      "240225.65930203832\n",
      "241933.8632231549\n",
      "239899.90563165044\n",
      "240459.8413171711\n",
      "240752.9736705139\n",
      "239783.74687789322\n",
      "240460.63553922973\n",
      "241169.21650226827\n",
      "241191.5377236755\n",
      "239878.20414935233\n",
      "240223.41588130803\n"
     ]
    }
   ],
   "source": [
    "# for문으로 bagging 구현\n",
    "\n",
    "import random\n",
    "\n",
    "bagging_predict_result = [] \n",
    "\n",
    "for _ in range(30):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0])\n",
    "    sm_train_x = train_x.iloc[random_data_index,]\n",
    "    sm_train_y = train_y.iloc[random_data_index,]\n",
    "    sm_train_x = sm.add_constant(sm_train_x, has_constant='add')\n",
    "    sm_model = sm.OLS(sm_train_y, sm_train_x)\n",
    "    fitted_sm_model = sm_model.fit()\n",
    "    pred = fitted_sm_model.predict(sm_test_x)\n",
    "    bagging_predict_result.append(pred)\n",
    "    print(sqrt(mean_squared_error(pred, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735      5.577809e+05\n",
       "2830     7.131169e+05\n",
       "4106     1.099635e+06\n",
       "16218    1.456560e+06\n",
       "19964    6.897132e+05\n",
       "             ...     \n",
       "12606    5.967845e+05\n",
       "14393    6.809664e+05\n",
       "6899     3.225181e+05\n",
       "85       8.959050e+05\n",
       "21363    4.302250e+05\n",
       "Length: 6484, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_predict = []\n",
    "\n",
    "for lst2_index in range(test_x.shape[0]):\n",
    "    temp_predict = []\n",
    "    \n",
    "    for lst_index in range(len(bagging_predict_result)):\n",
    "        temp_predict.append(bagging_predict_result[lst_index].values[lst2_index])\n",
    "        \n",
    "    bagging_predict.append(np.mean(temp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240029.03193371673"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(bagging_predict, test_y))\n",
    "# 이 경우는 Bagging 성능이 일반선형회귀 모델의 성능과 큰 차이가 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀모형에 적합 후 평가데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239804.29670858147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "linear_model1 = regression_model.fit(train_x, train_y)\n",
    "predict1= linear_model1.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict1, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging 을 이용하여 선형외귀모형에 적합 후 평가 (Sampling 5번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239976.66779136762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_model = BaggingRegressor(base_estimator=regression_model, n_estimators=5)\n",
    "linear_model2 = bagging_model.fit(train_x, train_y)\n",
    "predict2 = linear_model2.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict2, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플링을 많이하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239739.26886709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_model = BaggingRegressor(base_estimator=regression_model, n_estimators=30)\n",
    "linear_model3 = bagging_model.fit(train_x, train_y)\n",
    "predict3 = linear_model3.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict3, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터를 의사결정나무모형에 적합 후 평가데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294614.46462270856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_model = DecisionTreeRegressor()\n",
    "tree_model = decision_tree_model.fit(train_x, train_y)\n",
    "predict_tree = tree_model.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict_tree, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283162.7155177318\n",
      "307122.77061849815\n",
      "305018.3985194008\n",
      "294119.9780585983\n",
      "303144.89239704906\n",
      "290049.22651720856\n",
      "292085.65696765645\n",
      "338127.9994640701\n",
      "281161.9702999915\n",
      "302374.30424628634\n"
     ]
    }
   ],
   "source": [
    "# for문으로 bagging 구현\n",
    "import random\n",
    "bagging_predict_result = [] \n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0])\n",
    "    sm_train_x = train_x.iloc[random_data_index,]\n",
    "    sm_train_y = train_y.iloc[random_data_index,]\n",
    "    decision_tree_model = DecisionTreeRegressor()\n",
    "    tree_model = decision_tree_model.fit(sm_train_x, sm_train_y)\n",
    "    predict_tree = tree_model.predict(test_x)\n",
    "    bagging_predict_result.append(predict_tree)\n",
    "    print(sqrt(mean_squared_error(predict_tree, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_predict = []\n",
    "\n",
    "for lst2_index in range(test_x.shape[0]):\n",
    "    temp_predict = []\n",
    "    \n",
    "    for lst_index in range(len(bagging_predict_result)):\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index])\n",
    "        \n",
    "    bagging_predict.append(np.mean(temp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243689.7960536861"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(bagging_predict, test_y))\n",
    "# 위의 10개 개별 Tree 모델의 성능보다 Bagging 모델의 성능이 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging 패키지 활용해서 Tree 모형 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235580.73034317626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# 5번 샘플링 \n",
    "bagging_model = BaggingRegressor(base_estimator=decision_tree_model, n_estimators=5)\n",
    "linear_model4 = bagging_model.fit(train_x, train_y)\n",
    "predict4 = linear_model4.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict4, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238369.8101331218\n"
     ]
    }
   ],
   "source": [
    "# 10번 샘플링 \n",
    "bagging_model = BaggingRegressor(base_estimator=decision_tree_model, n_estimators=10)\n",
    "linear_model5 = bagging_model.fit(train_x, train_y)\n",
    "predict5 = linear_model5.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict5, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233660.9653609305\n"
     ]
    }
   ],
   "source": [
    "# 50번 샘플링 \n",
    "bagging_model = BaggingRegressor(base_estimator=decision_tree_model, n_estimators=50)\n",
    "linear_model6 = bagging_model.fit(train_x, train_y)\n",
    "predict6 = linear_model6.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict6, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230679.33347375528\n"
     ]
    }
   ],
   "source": [
    "# 100번 샘플링 \n",
    "bagging_model = BaggingRegressor(base_estimator=decision_tree_model, n_estimators=100)\n",
    "linear_model7 = bagging_model.fit(train_x, train_y)\n",
    "predict7 = linear_model7.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict7, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232308.17221605638\n"
     ]
    }
   ],
   "source": [
    "# 500번 샘플링 \n",
    "bagging_model = BaggingRegressor(base_estimator=decision_tree_model, n_estimators=500)\n",
    "linear_model8 = bagging_model.fit(train_x, train_y)\n",
    "predict8 = linear_model8.predict(test_x)\n",
    "\n",
    "print(sqrt(mean_squared_error(predict8, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n=> 모델의 샘플링 수가 증가할수록 예측성능은 좋아지지만, 특정 임계점 초과하는 경우에는 성능저하가 발생함\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "=> 모델의 샘플링 수가 증가할수록 예측성능은 좋아지지만, 특정 임계점 초과하는 경우에는 성능저하가 발생함\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
